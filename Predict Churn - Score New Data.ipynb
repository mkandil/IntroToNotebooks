{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "## Customer Churn Model Scoring\n#### The objectives of this lab is:\n- score **new** customer data against a pre-built model\n- schedule the notebook to run via the Notebook scheduler\n\n### Step 1: Download new customer data"}, {"cell_type": "code", "metadata": {}, "source": "import wget\nurl_customer='https://raw.githubusercontent.com/yfphoon/dsx_demo/master/data/new_customer_churn_data.csv'\n\n#remove existing files before downloading\n!rm -f new_customer_churn_data.csv\n\ncustomerFilename=wget.download(url_customer)\n\n!ls -l new_customer_churn_data.csv", "outputs": [{"output_type": "stream", "name": "stdout", "text": "-rw------- 1 sf94-47271e4efc25ab-4c4827746caf users 27597 Aug 11 15:12 new_customer_churn_data.csv\r\n"}], "execution_count": 2}, {"cell_type": "markdown", "metadata": {}, "source": "### Step 2: Read data into a Spark DataFrame\n**Note**: the new dataset does not contain the label column"}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "newData= sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(customerFilename)", "outputs": [], "execution_count": 3}, {"cell_type": "code", "metadata": {}, "source": "newData = newData.withColumnRenamed(\"Est Income\", \"EstIncome\").withColumnRenamed(\"Car Owner\",\"CarOwner\")\nnewData.toPandas().head()", "outputs": [{"metadata": {}, "output_type": "execute_result", "data": {"text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Gender</th>\n      <th>Status</th>\n      <th>Children</th>\n      <th>EstIncome</th>\n      <th>CarOwner</th>\n      <th>Age</th>\n      <th>LongDistance</th>\n      <th>International</th>\n      <th>Local</th>\n      <th>Dropped</th>\n      <th>Paymethod</th>\n      <th>LocalBilltype</th>\n      <th>LongDistanceBilltype</th>\n      <th>Usage</th>\n      <th>RatePlan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2048</td>\n      <td>F</td>\n      <td>S</td>\n      <td>1</td>\n      <td>13576.5</td>\n      <td>N</td>\n      <td>39.426667</td>\n      <td>14.83</td>\n      <td>0</td>\n      <td>25.66</td>\n      <td>0</td>\n      <td>CC</td>\n      <td>Budget</td>\n      <td>Standard</td>\n      <td>40.49</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2054</td>\n      <td>F</td>\n      <td>M</td>\n      <td>2</td>\n      <td>84166.1</td>\n      <td>N</td>\n      <td>54.013333</td>\n      <td>3.28</td>\n      <td>0</td>\n      <td>11.74</td>\n      <td>1</td>\n      <td>CC</td>\n      <td>Budget</td>\n      <td>Standard</td>\n      <td>15.02</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2075</td>\n      <td>F</td>\n      <td>S</td>\n      <td>0</td>\n      <td>68427.4</td>\n      <td>N</td>\n      <td>42.393333</td>\n      <td>23.76</td>\n      <td>0</td>\n      <td>50.05</td>\n      <td>0</td>\n      <td>Auto</td>\n      <td>FreeLocal</td>\n      <td>Standard</td>\n      <td>73.81</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2095</td>\n      <td>F</td>\n      <td>M</td>\n      <td>2</td>\n      <td>77551.1</td>\n      <td>Y</td>\n      <td>33.600000</td>\n      <td>20.53</td>\n      <td>0</td>\n      <td>41.89</td>\n      <td>1</td>\n      <td>CC</td>\n      <td>Budget</td>\n      <td>Intnl_discount</td>\n      <td>62.42</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2108</td>\n      <td>F</td>\n      <td>S</td>\n      <td>1</td>\n      <td>13109.1</td>\n      <td>N</td>\n      <td>62.606667</td>\n      <td>22.38</td>\n      <td>0</td>\n      <td>40.48</td>\n      <td>0</td>\n      <td>Auto</td>\n      <td>Budget</td>\n      <td>Standard</td>\n      <td>62.87</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "     ID Gender Status  Children  EstIncome CarOwner        Age  LongDistance  \\\n0  2048      F      S         1    13576.5        N  39.426667         14.83   \n1  2054      F      M         2    84166.1        N  54.013333          3.28   \n2  2075      F      S         0    68427.4        N  42.393333         23.76   \n3  2095      F      M         2    77551.1        Y  33.600000         20.53   \n4  2108      F      S         1    13109.1        N  62.606667         22.38   \n\n   International  Local  Dropped Paymethod LocalBilltype LongDistanceBilltype  \\\n0              0  25.66        0        CC        Budget             Standard   \n1              0  11.74        1        CC        Budget             Standard   \n2              0  50.05        0      Auto     FreeLocal             Standard   \n3              0  41.89        1        CC        Budget       Intnl_discount   \n4              0  40.48        0      Auto        Budget             Standard   \n\n   Usage  RatePlan  \n0  40.49         1  \n1  15.02         2  \n2  73.81         3  \n3  62.42         2  \n4  62.87         1  "}, "execution_count": 4}], "execution_count": 4}, {"cell_type": "markdown", "metadata": {}, "source": "### Step 3: Load Saved Model\nLoad model in Object Storage."}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "from pyspark.ml import PipelineModel\nmodel1_loaded = PipelineModel.load(\"PredictChurn.churnModel\")", "outputs": [], "execution_count": 5}, {"cell_type": "markdown", "metadata": {}, "source": "### Step 4: Score the new data\nNote: The scored output contains the predicted values and confidence scores"}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "result = model1_loaded.transform(newData)", "outputs": [], "execution_count": 6}, {"cell_type": "markdown", "metadata": {}, "source": "### Step 5: Export Score into a csv file"}, {"cell_type": "code", "metadata": {}, "source": "#Select ID, prediction and probability fields from the result dataframe\n\nr1=result.select(result[\"ID\"],result[\"predictedLabel\"],result[\"prediction\"],result[\"probability\"])\nr1.show(5,False)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----+--------------+----------+------------------------------------------+\n|ID  |predictedLabel|prediction|probability                               |\n+----+--------------+----------+------------------------------------------+\n|2048|T             |1.0       |[0.019912822658724294,0.9800871773412757] |\n|2054|T             |1.0       |[0.27537695698434417,0.7246230430156559]  |\n|2075|F             |0.0       |[1.0,0.0]                                 |\n|2095|F             |0.0       |[0.9365642172419282,0.0634357827580719]   |\n|2108|T             |1.0       |[0.0018529893529893534,0.9981470106470107]|\n+----+--------------+----------+------------------------------------------+\nonly showing top 5 rows\n\n"}], "execution_count": 7}, {"cell_type": "markdown", "metadata": {}, "source": "#### Decompose the probability column\nThe probability column contains a vector for each record, and the elements must be extracted"}, {"cell_type": "code", "metadata": {}, "source": "from pyspark.sql import Row\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.sql.functions import udf\nfrom pyspark.ml.linalg import Vectors\n\nudf_0 = udf(lambda vector: float(vector[0]), DoubleType())\nudf_1 = udf(lambda vector: float(vector[1]), DoubleType())\n\nr2 = (r1.select(r1[\"ID\"], r1[\"prediction\"],r1[\"probability\"])\n    .withColumn('probability_0', udf_0(r1.probability))\n    .withColumn('probability_1', udf_1(r1.probability))\n    .drop(\"probability\"))\n\nr2.show(10, False)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----+----------+---------------------+--------------------+\n|ID  |prediction|probability_0        |probability_1       |\n+----+----------+---------------------+--------------------+\n|2048|1.0       |0.019912822658724294 |0.9800871773412757  |\n|2054|1.0       |0.27537695698434417  |0.7246230430156559  |\n|2075|0.0       |1.0                  |0.0                 |\n|2095|0.0       |0.9365642172419282   |0.0634357827580719  |\n|2108|1.0       |0.0018529893529893534|0.9981470106470107  |\n|2124|0.0       |0.995243288590604    |0.004756711409395973|\n|2154|1.0       |0.13510869565217393  |0.8648913043478261  |\n|2218|0.0       |0.9820768344696615   |0.01792316553033841 |\n|2267|0.0       |0.9756357043893127   |0.024364295610687297|\n|2284|1.0       |0.06202317290552585  |0.937976827094474   |\n+----+----------+---------------------+--------------------+\nonly showing top 10 rows\n\n"}], "execution_count": 8}, {"cell_type": "markdown", "metadata": {}, "source": "#### Connect to Object Storage\nIn order to write the scores to Object Storage, specify the credentials to connect to your instance of Object Storage.  The easiet way to do that is:\n- If you do not already have a file in Object Storage, load a file into it using the **Files** interface\n- Choose \"*Insert SparkSession DataFame*\" to generate the credentials and code to connect to Object Storage\n\n![Load Files](https://raw.githubusercontent.com/yfphoon/IntroToNotebooks/master/images/upload_files.png)\n\n- Edit the code to comment out or edit the code that reads the file.  The edited code cell should look like this\n\n![credentials](https://raw.githubusercontent.com/yfphoon/IntroToNotebooks/master/images/generated_credentials.png)\n\n"}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "# insert code here\n\n", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "#### Write sores .csv file"}, {"cell_type": "markdown", "metadata": {}, "source": "The code cell below specifies the options for saving the csv file.  Check that you have specified the **TARGET_CONTAINER** to point to your project."}, {"cell_type": "code", "metadata": {}, "source": "from ingest.Connectors import Connectors\n\nobjectstoresaveOptions = {\n        Connectors.BluemixObjectStorage.AUTH_URL          : credentials['auth_url'],\n        Connectors.BluemixObjectStorage.USERID            : credentials['user_id'],\n        Connectors.BluemixObjectStorage.PASSWORD          : credentials['password'],\n        Connectors.BluemixObjectStorage.PROJECTID         : credentials['project_id'],\n        Connectors.BluemixObjectStorage.REGION            : credentials['region'],\n        Connectors.BluemixObjectStorage.TARGET_CONTAINER  : 'IntroToNotebooks',\n        Connectors.BluemixObjectStorage.TARGET_FILE_NAME  : 'churn_scores.csv',\n        Connectors.BluemixObjectStorage.TARGET_WRITE_MODE : 'write'}\n\n\nr2.write.format(\"com.ibm.spark.discover\").options(**objectstoresaveOptions).save()", "outputs": [], "execution_count": 28}, {"cell_type": "code", "metadata": {}, "source": "r3 = spark.read\\\n  .format('csv')\\\n  .load(bmos.url('IntroToNotebooks', 'churn_scores.csv'))\nr3.select(r3[\"_c0\"].alias(\"ID\"), r3[\"_c1\"].alias(\"prediction\"), r3[\"_c2\"].alias(\"probability_0\"), r3[\"_c3\"].alias(\"probability_1\")).show(5, False)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----+----------+---------------------+------------------+\n|ID  |prediction|probability_0        |probability_1     |\n+----+----------+---------------------+------------------+\n|2048|1.0       |0.019912822658724294 |0.9800871773412757|\n|2054|1.0       |0.27537695698434417  |0.7246230430156559|\n|2075|0.0       |1.0                  |0.0               |\n|2095|0.0       |0.9365642172419282   |0.0634357827580719|\n|2108|1.0       |0.0018529893529893534|0.9981470106470107|\n+----+----------+---------------------+------------------+\nonly showing top 5 rows\n\n"}], "execution_count": 33}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": "### Step 6: Schedule this notebook to run at a time and frequency of your choice\nClick on the \"clock\" icon at the top right"}, {"cell_type": "markdown", "metadata": {}, "source": "You have come to the end of this notebook"}, {"cell_type": "markdown", "metadata": {}, "source": "** Sidney Phoon** <br/>\nyfphoon@us.ibm.com<br/>\nAug, 2017"}], "metadata": {"kernelspec": {"display_name": "Python 2 with Spark 2.0", "name": "python2-spark20", "language": "python"}, "language_info": {"codemirror_mode": {"version": 2, "name": "ipython"}, "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython2", "version": "2.7.11", "file_extension": ".py", "nbconvert_exporter": "python"}}, "nbformat_minor": 1, "nbformat": 4}